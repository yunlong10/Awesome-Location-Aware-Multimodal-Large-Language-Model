# Awesome-Location-Aware-Multimodal-Large-Language-Model [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

## Location Aware MLLMs

### Regional Location

- **GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest**\
  `arXiv 07/2023` [[paper]](https://arxiv.org/abs/2307.03601)

- **Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic**\
  `arXiv 07/2023` [[paper]](https://arxiv.org/abs/2306.15195)

- **Kosmos-2: Grounding Multimodal Large Language Models to the World**\
  `arXiv 06/2023` [[paper]](https://arxiv.org/abs/2306.14824)

### Point Location

- **Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic**\
  `arXiv 07/2023` [[paper]](https://arxiv.org/abs/2306.15195)

### Temporal Location

- **Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning**\
  `CVPR 23` [[paper]](https://arxiv.org/abs/2302.14115)

- **ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System**\
  `arXiv 04/2023` [[paper]](https://arxiv.org/abs/2304.14407)

## Dataset
